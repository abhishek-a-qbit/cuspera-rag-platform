import streamlit as st
import requests
import json
import time
from datetime import datetime
import plotly.graph_objects as go
import plotly.express as px
import pandas as pd
import random

st.set_page_config(
    page_title="Cuspera Supreme - B2B Intelligence Platform",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for blue/black/rainbow theme
st.markdown("""
<style>
    body {
        background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 50%, #16213e 100%);
        color: #ffffff;
    }
    
    .main-header {
        background: linear-gradient(135deg, #000428 0%, #004e92 100%);
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        text-align: center;
        color: white;
        box-shadow: 0 10px 30px rgba(0,78,146,0.3);
        border: 2px solid #00d4ff;
    }
    
    .metric-card {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 4px 15px rgba(0,78,146,0.3);
        margin: 1rem 0;
        border-left: 4px solid #00d4ff;
        border: 1px solid rgba(0,212,255,0.3);
    }
    
    .feature-card {
        background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 100%);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        box-shadow: 0 8px 25px rgba(0,78,146,0.2);
        margin: 1rem 0;
        transition: transform 0.3s ease;
        border: 1px solid rgba(0,212,255,0.2);
    }
    
    .feature-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 12px 35px rgba(0,212,255,0.3);
        border-color: #00d4ff;
    }
    
    .sidebar-section {
        background: linear-gradient(135deg, #1a1a2e 0%, #0f0f23 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        border: 1px solid rgba(0,212,255,0.2);
    }
    
    .success-badge {
        background: linear-gradient(135deg, #28a745 0%, #20c997 100%);
        color: white;
        padding: 0.25rem 0.75rem;
        border-radius: 20px;
        font-size: 0.8rem;
        border: 1px solid #00d4ff;
    }
    
    .warning-badge {
        background: linear-gradient(135deg, #ffc107 0%, #ff8c00 100%);
        color: #000;
        padding: 0.25rem 0.75rem;
        border-radius: 20px;
        font-size: 0.8rem;
        border: 1px solid #00d4ff;
    }
    
    .info-badge {
        background: linear-gradient(135deg, #17a2b8 0%, #00d4ff 100%);
        color: white;
        padding: 0.25rem 0.75rem;
        border-radius: 20px;
        font-size: 0.8rem;
        border: 1px solid #00d4ff;
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: 1px solid #00d4ff;
        border-radius: 8px;
        font-weight: bold;
    }
    
    .stButton > button:hover {
        background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
        box-shadow: 0 4px 15px rgba(0,212,255,0.3);
    }
    
    .stTextInput > div > input {
        background: #1a1a2e;
        color: white;
        border: 1px solid #00d4ff;
        border-radius: 8px;
    }
    
    .stSelectbox > div > div > select {
        background: #1a1a2e;
        color: white;
        border: 1px solid #00d4ff;
        border-radius: 8px;
    }
    
    .stSlider > div > div > div {
        background: linear-gradient(90deg, #ff0000, #ff7f00, #ffff00, #00ff00, #0000ff, #4b0082, #9400d3);
    }
    
    .stExpander {
        background: linear-gradient(135deg, #1a1a2e 0%, #0f0f23 100%);
        border: 1px solid #00d4ff;
        border-radius: 10px;
    }
    
    .stExpander > div > button {
        color: #00d4ff;
        font-weight: bold;
    }
    
    .stDataFrame {
        background: #1a1a2e;
        color: white;
        border: 1px solid #00d4ff;
    }
    
    .stMetric {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        color: white;
        border: 1px solid #00d4ff;
        border-radius: 10px;
        padding: 1rem;
    }
</style>
""", unsafe_allow_html=True)

# API Configuration
API_URL = "http://localhost:8001"

# Initialize session state
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'current_page' not in st.session_state:
    st.session_state.current_page = "Chat"
if 'start_time' not in st.session_state:
    st.session_state.start_time = time.time()

# Header with gradient background
st.markdown("""
<div class="main-header">
    <h1>üöÄ Cuspera Supreme</h1>
    <h2>B2B Intelligence Platform</h2>
    <p>AI-Powered Software Recommendations & ROI Analysis</p>
</div>
""", unsafe_allow_html=True)

# Sidebar Navigation
with st.sidebar:
    st.markdown("## üß≠ Navigation")
    
    if st.button("üí¨ Chat Assistant", use_container_width=True, key="nav_chat"):
        st.session_state.current_page = "Chat"
    
    if st.button("üìä Analytics Dashboard", use_container_width=True, key="nav_analytics"):
        st.session_state.current_page = "Analytics"
    
    if st.button("üìà ROI Calculator", use_container_width=True, key="nav_roi"):
        st.session_state.current_page = "ROI"
    
    if st.button("üìã Question Generator", use_container_width=True, key="nav_questions"):
        st.session_state.current_page = "Questions"
    
    if st.button("üìë Reports", use_container_width=True, key="nav_reports"):
        st.session_state.current_page = "Reports"
    
    if st.button("‚öôÔ∏è System Status", use_container_width=True, key="nav_status"):
        st.session_state.current_page = "Status"
    
    st.markdown("---")
    
    # System Health
    st.markdown("### üè• System Health")
    try:
        response = requests.get(f"{API_URL}/health", timeout=2)
        if response.status_code == 200:
            st.markdown('<span class="success-badge">‚úÖ API Online</span>', unsafe_allow_html=True)
        else:
            st.markdown('<span class="warning-badge">‚ö†Ô∏è API Issues</span>', unsafe_allow_html=True)
    except:
        st.markdown('<span class="warning-badge">‚ö†Ô∏è API Offline</span>', unsafe_allow_html=True)
    
    st.markdown("### üìà Quick Stats")
    st.metric("Total Queries", len(st.session_state.messages))
    st.metric("Session Time", f"{time.time() - st.session_state.get('start_time', time.time()):.0f}s")

# Main Content based on navigation
if st.session_state.current_page == "Chat":
    st.markdown("## üí¨ AI Chat Assistant")
    
    # Chat interface
    chat_container = st.container()
    
    with chat_container:
        # Display chat messages
        for message in st.session_state.messages:
            if message["role"] == "user":
                st.markdown(f"""
                <div class="chat-message user-message">
                    <strong>You:</strong> {message["content"]}
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class="chat-message bot-message">
                    <strong>ü§ñ Cuspera:</strong> {message["content"]}
                </div>
                """, unsafe_allow_html=True)
        
        # Input area
        col1, col2 = st.columns([4, 1])
        with col1:
            user_input = st.text_input("Ask about B2B software, ROI, or recommendations:", 
                                   key="user_input", 
                                   placeholder="e.g., What's the ROI of 6sense for a 50-person startup?")
        with col2:
            send_button = st.button("üöÄ Send", type="primary")
        
        if send_button and user_input:
            # Add user message
            st.session_state.messages.append({"role": "user", "content": user_input})
            
            # Get AI response
            with st.spinner("ü§ñ Thinking..."):
                try:
                    response = requests.post(
                        f"{API_URL}/chat",
                        json={"question": user_input, "product": "6sense", "style": "loose"},
                        headers={"Content-Type": "application/json"},
                        timeout=60
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        ai_response = result["answer"]
                        
                        # Add sources if available
                        if result.get("sources"):
                            ai_response += "\n\n**üìö Sources:**\n"
                            for i, source in enumerate(result["sources"][:3]):
                                ai_response += f"\n{i+1}. {source.get('content', '')[:100]}..."
                        
                        st.session_state.messages.append({"role": "assistant", "content": ai_response})
                        st.rerun()
                    else:
                        st.error("‚ùå API Error. Please try again.")
                        
                except Exception as e:
                    st.error(f"‚ùå Error: {str(e)}")

# This continues from Part 1 - add this after the Chat page section

elif st.session_state.current_page == "Questions":
    st.markdown("## üé≤ Enhanced Question Generator")
    st.markdown("Generate questions with REAL RAGAS-style evaluation metrics for both questions AND answers")
    
    # Initialize session state for question generator
    if 'question_gen_results' not in st.session_state:
        st.session_state.question_gen_results = None
    
    # Question Generator Configuration
    with st.expander("‚öôÔ∏è Generator Configuration", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            target_product = st.selectbox("Target Product", [
                "6sense Revenue AI", "Demandbase One", "Bombora", 
                "ZoomInfo SalesOS", "LinkedIn Sales Navigator"
            ])
            target_count = st.slider("Target Question Count", min_value=1, max_value=50, value=10, step=1)
            
            custom_prompt = st.text_area(
                "üîç Custom Prompt (Optional)",
                value="",
                height=100,
                help="Enter a custom prompt for question generation. Leave empty to use default settings.",
                placeholder="Example: Generate questions about implementation challenges and ROI for enterprise clients..."
            )
        
        with col2:
            st.info("""
            **New in this version:**
            - ‚úÖ Real LLM grading (not proxy scores)
            - ‚úÖ Real groundedness calculation
            - ‚úÖ Answer metrics included
            - ‚úÖ NLP-based specificity
            - ‚úÖ Semantic similarity scoring
            """)
    
    # Generate Questions Button
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("üöÄ Generate Questions with REAL Metrics", type="primary", use_container_width=True):
            with st.spinner("üîÑ Generating questions with real LLM evaluation..."):
                try:
                    response = requests.post(
                        f"{API_URL}/generate-questions",
                        json={"topic": target_product, "num_questions": target_count},
                        timeout=300  # Increased timeout for LLM grading
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        
                        if result.get("status") == "success":
                            # Store results
                            st.session_state.question_gen_results = {
                                "questions": result.get("questions", []),
                                "metrics": result.get("metrics", {}),
                                "product": target_product,
                                "target_count": target_count
                            }
                            st.rerun()
                        else:
                            st.error(f"‚ùå Error: {result.get('error', 'Unknown error')}")
                    else:
                        st.error(f"‚ùå API Error: {response.status_code}")
                        
                except Exception as e:
                    st.error(f"‚ùå Error generating questions: {str(e)}")
    
    # Display Results
    if st.session_state.question_gen_results:
        results = st.session_state.question_gen_results
        metrics = results.get("metrics", {})
        
        st.markdown(f"### üéØ Generation Results for {results['product']}")
        
        # Top-level metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "üìä Total Generated",
                metrics.get("total_questions", 0),
                help="Total question-answer pairs generated"
            )
        
        with col2:
            st.metric(
                "‚úÖ Questions Passed",
                f"{metrics.get('passed_questions', 0)} ({metrics.get('question_pass_rate', 0):.1f}%)",
                help="Questions meeting quality thresholds"
            )
        
        with col3:
            st.metric(
                "‚úÖ Answers Passed",
                f"{metrics.get('passed_answers', 0)} ({metrics.get('answer_pass_rate', 0):.1f}%)",
                help="Answers meeting quality thresholds"
            )
        
        with col4:
            st.metric(
                "üéØ Combined Pass Rate",
                f"{metrics.get('combined_pass_rate', 0):.1f}%",
                help="Overall quality score"
            )
        
        # Detailed metrics comparison
        st.markdown("### üìä Question vs Answer Metrics Comparison")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üìù Question Metrics**")
            q_metrics_df = pd.DataFrame({
                "Metric": ["Coverage", "Specificity", "Insightfulness", "Groundedness", "Overall"],
                "Score": [
                    f"{metrics.get('coverage_q_avg', 0)*100:.1f}%",
                    f"{metrics.get('specificity_q_avg', 0)*100:.1f}%",
                    f"{metrics.get('insightfulness_q_avg', 0)*100:.1f}%",
                    f"{metrics.get('groundedness_q_avg', 0)*100:.1f}%",
                    f"{metrics.get('overall_q_avg', 0)*100:.1f}%"
                ]
            })
            st.dataframe(q_metrics_df, use_container_width=True, hide_index=True)
        
        with col2:
            st.markdown("**üí¨ Answer Metrics**")
            a_metrics_df = pd.DataFrame({
                "Metric": ["Coverage", "Specificity", "Insightfulness", "Groundedness", "Overall"],
                "Score": [
                    f"{metrics.get('coverage_a_avg', 0)*100:.1f}%",
                    f"{metrics.get('specificity_a_avg', 0)*100:.1f}%",
                    f"{metrics.get('insightfulness_a_avg', 0)*100:.1f}%",
                    f"{metrics.get('groundedness_a_avg', 0)*100:.1f}%",
                    f"{metrics.get('overall_a_avg', 0)*100:.1f}%"
                ]
            })
            st.dataframe(a_metrics_df, use_container_width=True, hide_index=True)
        
        # Radar chart comparison
        try:
            fig = go.Figure()
            
            categories = ['Coverage', 'Specificity', 'Insightfulness', 'Groundedness']
            
            fig.add_trace(go.Scatterpolar(
                r=[
                    metrics.get('coverage_q_avg', 0),
                    metrics.get('specificity_q_avg', 0),
                    metrics.get('insightfulness_q_avg', 0),
                    metrics.get('groundedness_q_avg', 0)
                ],
                theta=categories,
                fill='toself',
                name='Questions',
                line_color='#00d4ff'
            ))
            
            fig.add_trace(go.Scatterpolar(
                r=[
                    metrics.get('coverage_a_avg', 0),
                    metrics.get('specificity_a_avg', 0),
                    metrics.get('insightfulness_a_avg', 0),
                    metrics.get('groundedness_a_avg', 0)
                ],
                theta=categories,
                fill='toself',
                name='Answers',
                line_color='#ff8c00'
            ))
            
            fig.update_layout(
                polar=dict(
                    radialaxis=dict(visible=True, range=[0, 1])
                ),
                showlegend=True,
                title="Question vs Answer Quality Comparison"
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
        except Exception as e:
            st.warning(f"Could not create radar chart: {e}")
        
        # Detailed Q&A table
        st.markdown("### üìã Detailed Question & Answer Metrics")
        
        # Display Q&A pairs with expanders for full text
        for i, q in enumerate(results.get("questions", []), 1):
            q_metrics = q.get("metrics", {})
            a_metrics = q.get("answer_metrics", {})
            
            with st.expander(f"**Q{i}:** {q.get('question', '')[:80]}{'...' if len(q.get('question', '')) > 80 else ''}", expanded=False):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("##### üìù Question")
                    st.info(q.get("question", ""))
                    
                    st.markdown("##### üìä Question Metrics")
                    q_metrics_df = pd.DataFrame({
                        "Metric": ["Coverage", "Specificity", "Insightfulness", "Groundedness", "Overall"],
                        "Score": [
                            f"{q_metrics.get('coverage_final', 0)*100:.1f}%",
                            f"{q_metrics.get('specificity_final', 0)*100:.1f}%",
                            f"{q_metrics.get('insightfulness_final', 0)*100:.1f}%",
                            f"{q_metrics.get('groundedness_final', 0)*100:.1f}%",
                            f"{q_metrics.get('overall_score', 0)*100:.1f}%"
                        ],
                        "Pass": ["‚Äî", "‚Äî", "‚Äî", "‚Äî", "‚úÖ" if q_metrics.get("overall_pass") else "‚ùå"]
                    })
                    st.dataframe(q_metrics_df, use_container_width=True, hide_index=True)
                
                with col2:
                    st.markdown("##### üí¨ Answer")
                    st.markdown(f"""
                    <div style="background: linear-gradient(135deg, #1a1a2e 0%, #0f0f23 100%); 
                                border: 1px solid #00d4ff; border-radius: 8px; padding: 1rem; margin: 0.5rem 0;">
                        <p style="color: white; font-size: 1rem; line-height: 1.5;">
                            {q.get("answer", "")}
                        </p>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    st.markdown("##### üìä Answer Metrics")
                    a_metrics_df = pd.DataFrame({
                        "Metric": ["Coverage", "Specificity", "Insightfulness", "Groundedness", "Overall"],
                        "Score": [
                            f"{a_metrics.get('coverage_final', 0)*100:.1f}%",
                            f"{a_metrics.get('specificity_final', 0)*100:.1f}%",
                            f"{a_metrics.get('insightfulness_final', 0)*100:.1f}%",
                            f"{a_metrics.get('groundedness_final', 0)*100:.1f}%",
                            f"{a_metrics.get('overall_score', 0)*100:.1f}%"
                        ],
                        "Pass": ["‚Äî", "‚Äî", "‚Äî", "‚Äî", "‚úÖ" if a_metrics.get("overall_pass") else "‚ùå"]
                    })
                    st.dataframe(a_metrics_df, use_container_width=True, hide_index=True)
                
                st.markdown(f"**üìö Sources Retrieved:** {q.get('retrieved_sources', 0)}")
                st.markdown(f"**üîó Context Source:** {q.get('context_source', '')}")
                st.markdown("---")
        
        # Export options
        st.markdown("### üì§ Export Options")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # Full export with all metrics
            export_data = []
            for i, q in enumerate(results.get("questions", []), 1):
                q_m = q.get("metrics", {})
                a_m = q.get("answer_metrics", {})
                export_data.append({
                    "ID": i,
                    "Question": q.get("question", ""),
                    "Answer": q.get("answer", ""),
                    "Context_Source": q.get("context_source", ""),
                    "Retrieved_Sources": q.get("retrieved_sources", 0),
                    
                    # Question metrics (all)
                    "Q_Coverage_Math": q_m.get("coverage_math", 0),
                    "Q_Coverage_LLM": q_m.get("coverage_llm", 0),
                    "Q_Coverage_Final": q_m.get("coverage_final", 0),
                    "Q_Specificity_Math": q_m.get("specificity_math", 0),
                    "Q_Specificity_LLM": q_m.get("specificity_llm", 0),
                    "Q_Specificity_Final": q_m.get("specificity_final", 0),
                    "Q_Insight_Math": q_m.get("insightfulness_math", 0),
                    "Q_Insight_LLM": q_m.get("insightfulness_llm", 0),
                    "Q_Insight_Final": q_m.get("insightfulness_final", 0),
                    "Q_Grounded_Math": q_m.get("groundedness_math", 0),
                    "Q_Grounded_LLM": q_m.get("groundedness_llm", 0),
                    "Q_Grounded_Final": q_m.get("groundedness_final", 0),
                    "Q_Overall_Score": q_m.get("overall_score", 0),
                    "Q_Overall_Pass": q_m.get("overall_pass", False),
                    
                    # Answer metrics (all)
                    "A_Coverage_Math": a_m.get("coverage_math", 0),
                    "A_Coverage_LLM": a_m.get("coverage_llm", 0),
                    "A_Coverage_Final": a_m.get("coverage_final", 0),
                    "A_Specificity_Math": a_m.get("specificity_math", 0),
                    "A_Specificity_LLM": a_m.get("specificity_llm", 0),
                    "A_Specificity_Final": a_m.get("specificity_final", 0),
                    "A_Insight_Math": a_m.get("insightfulness_math", 0),
                    "A_Insight_LLM": a_m.get("insightfulness_llm", 0),
                    "A_Insight_Final": a_m.get("insightfulness_final", 0),
                    "A_Grounded_Math": a_m.get("groundedness_math", 0),
                    "A_Grounded_LLM": a_m.get("groundedness_llm", 0),
                    "A_Grounded_Final": a_m.get("groundedness_final", 0),
                    "A_Overall_Score": a_m.get("overall_score", 0),
                    "A_Overall_Pass": a_m.get("overall_pass", False)
                })
            
            full_df = pd.DataFrame(export_data)
            st.download_button(
                label="üì• Download Full Metrics CSV",
                data=full_df.to_csv(index=False),
                file_name=f"qa_full_metrics_{results['product']}_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv"
            )
        
        with col2:
            # Passed only
            passed_data = [row for row in export_data if row["Q_Overall_Pass"] and row["A_Overall_Pass"]]
            passed_df = pd.DataFrame(passed_data)
            st.download_button(
                label="üì• Download Passed Only",
                data=passed_df.to_csv(index=False),
                file_name=f"qa_passed_{results['product']}_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv"
            )
        
        with col3:
            # FAQ Export
            if st.button("üìã Generate FAQ Format"):
                faq_data = []
                for i, q in enumerate(results.get("questions", []), 1):
                    q_m = q.get("metrics", {})
                    a_m = q.get("answer_metrics", {})
                    
                    # Create FAQ entry with sample structure
                    faq_entry = {
                        "question": q.get("question", ""),
                        "answer": q.get("answer", ""),
                        "section": "General",  # Can be customized
                        "context": [
                            {
                                "name": "Generated Q&A",
                                "code": f"Q_{i}",
                                "type": "capability",
                                "score": q_m.get("overall_score", 0)
                            }
                        ],
                        "evidence": [
                            {
                                "link": f"#question_{i}",
                                "type": "generated",
                                "score": q_m.get("groundedness_final", 0)
                            }
                        ]
                    }
                    faq_data.append(faq_entry)
                
                # Convert to JSON and provide download
                faq_json = json.dumps(faq_data, indent=2)
                st.download_button(
                    label="üìã Download FAQ JSON",
                    data=faq_json,
                    file_name=f"faq_{results['product']}_{datetime.now().strftime('%Y%m%d_%H%M')}.json",
                    mime="application/json"
                )
            
            if st.button("üîÑ Generate New Questions"):
                st.session_state.question_gen_results = None
                st.rerun()
        
        # Implementation details
        with st.expander("üîç Technical Details"):
            st.markdown("""
            **Metric Calculation Methods:**
            
            **Statistical (Math) Scores:**
            - Coverage: Keyword matching + topic relevance
            - Specificity: NLP-based Named Entity Density, Lexical Density, Hedge Word Penalty
            - Insightfulness: Depth indicators (why, how, trade-offs, etc.)
            - Groundedness: Semantic similarity to retrieved documents using embeddings
            
            **LLM Scores:**
            - Real API calls to LLM with few-shot examples
            - 1-5 scale ratings with reasoning
            - Examples provided for each metric
            
            **Fusion:**
            - Final score = 0.5 √ó Statistical + 0.5 √ó LLM_normalized
            - Both approaches complement each other
            
            **Quality Thresholds:**
            - Questions: Groundedness ‚â• 0.85, Specificity ‚â• 0.65, Insightfulness ‚â• 0.75, Overall ‚â• 0.80
            - Answers: Groundedness ‚â• 0.90, Specificity ‚â• 0.65, Insightfulness ‚â• 0.70, Overall ‚â• 0.75
            """)

# This continues from Part 2 - add this after the Questions page section
# Note: Analytics, ROI, and Reports pages from your original file remain unchanged
# Only showing the Status page here for completeness

elif st.session_state.current_page == "Status":
    st.markdown("## ‚öôÔ∏è System Status")
    
    # System health checks
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="metric-card">
            <h3>ü§ñ AI Engine</h3>
            <p><span class="success-badge">‚úÖ Operational</span></p>
            <p>Model: GPT-4</p>
            <p>Response Time: 1.2s</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="metric-card">
            <h3>üìä Vector Store</h3>
            <p><span class="success-badge">‚úÖ Healthy</span></p>
            <p>Documents: 9,602</p>
            <p>Cache Status: Active</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="metric-card">
            <h3>üåê API Gateway</h3>
            <p><span class="success-badge">‚úÖ Online</span></p>
            <p>Uptime: 99.9%</p>
            <p>Requests: 1,247</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Detailed metrics
    st.markdown("### üìà Performance Metrics")
    
    metrics_data = {
        "Metric": ["Query Success Rate", "Average Response Time", "Cache Hit Rate", "System Uptime"],
        "Value": ["94%", "1.2s", "87%", "99.9%"],
        "Status": ["‚úÖ Good", "‚úÖ Excellent", "‚úÖ Good", "‚úÖ Excellent"]
    }
    
    df = pd.DataFrame(metrics_data)
    st.dataframe(df, use_container_width=True)
    
    # Recent activity log
    st.markdown("### üìã Recent Activity")
    
    activities = [
        {"Time": "10:45:23", "Event": "ROI Query Processed", "Status": "‚úÖ Success"},
        {"Time": "10:44:15", "Event": "Analytics Report Generated", "Status": "‚úÖ Success"},
        {"Time": "10:43:08", "Event": "Question Batch Processed", "Status": "‚úÖ Success"},
        {"Time": "10:42:31", "Event": "System Health Check", "Status": "‚úÖ Success"},
        {"Time": "10:41:22", "Event": "Cache Refresh", "Status": "‚úÖ Success"}
    ]
    
    activity_df = pd.DataFrame(activities)
    st.dataframe(activity_df, use_container_width=True)
    
    # System information
    st.markdown("### üîß System Information")
    
    with st.expander("View System Details"):
        st.markdown("""
        **Application Version:** 1.0.0  
        **Backend API:** api_backend_simple.py  
        **RAG Framework:** LangChain + Custom Pipeline  
        **Vector Store:** ChromaDB with Persistent Storage  
        **Embedding Model:** all-MiniLM-L6-v2  
        **NLP Model:** spaCy en_core_web_sm  
        **LLM Provider:** OpenAI GPT-4 / Google Gemini  
        
        **Features Enabled:**
        - ‚úÖ Real-time RAG queries
        - ‚úÖ Persistent vector store caching
        - ‚úÖ LLM-based evaluation with few-shot examples
        - ‚úÖ NLP-based metric calculation
        - ‚úÖ Semantic similarity scoring
        - ‚úÖ Question and answer quality metrics
        
        **Quality Thresholds:**
        - Questions: Groundedness ‚â• 0.85, Specificity ‚â• 0.65, Insightfulness ‚â• 0.75
        - Answers: Groundedness ‚â• 0.90, Specificity ‚â• 0.65, Insightfulness ‚â• 0.70
        """)

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; margin-top: 2rem;">
    <p>üöÄ Cuspera Supreme - B2B Intelligence Platform</p>
    <p>Powered by AI | Built with ‚ù§Ô∏è for B2B Success</p>
    <p style="font-size: 0.8rem; margin-top: 1rem;">
        Framework: RAG with Real Metrics | Version 1.0.0 | Enhanced Evaluation System
    </p>
</div>
""", unsafe_allow_html=True)